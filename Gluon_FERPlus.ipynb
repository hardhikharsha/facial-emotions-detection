@@ -44,8 +44,7 @@
   "source": [
    "# Processed Data - FER+\n",
    "\n",
    "Follow the instructions listed in the README file - https://github.com/TalkAI/facial-emotion-recognition-gluon#before-you-start",
    "\n",
    "Follow the instructions listed in the README file - https://github.com/TalkAI/facial-emotion-recognition-gluon#before-you-start\n",
    "* FER+ has new corrected labels\n",
    "* FER+ has 8 emotions - (0: 'neutral', 1: 'happiness', 2: 'surprise', 3: 'sadness', 4: 'anger', 5: 'disgust', 6: 'fear',7: 'contempt')\n",
    "* Image augmentations:\n",
@@ -75,7 +74,7 @@
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
@@ -1071,7 +1070,7 @@
    "# There will be 2 files exported: \n",
    "# 1) gluon_ferplus-symbol.json => Contains the network definition\n",
    "# 2) gluon_ferplus-0000.params => Contains the weights in the network\n",
    "net.export('gluon_ferplus')"
    "net.export('fer')"
   ]
  },
  {
@@ -1090,6 +1089,7 @@
   "outputs": [],
   "source": [
    "!pip install mxnet-model-server\n",
    "!pip install model-archiver\n",
    "!pip install scikit-image\n",
    "!pip install opencv-python"
   ]
@@ -1111,10 +1111,10 @@
   "source": [
    "# As a first step, we will download the pre-trained model. \n",
    "# You can skip this step if you have just trained your model, but then you will need to copy the model files into ferplus directory\n",
    "!mkdir ferplus\n",
    "%cd ferplus\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/gluon_ferplus-0000.params\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/gluon_ferplus-symbol.json"
    "!mkdir fer\n",
    "%cd fer\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/fer-0000.params\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/fer-symbol.json"
   ]
  },
  {
@@ -1164,8 +1164,9 @@
   "outputs": [],
   "source": [
    "# Let's package everything up into a Model Archive bundle\n",
    "!mxnet-model-export --model-name ferplus --service-file-path ./fer_service.py --model-path .\n",
    "!ls -l ferplus.model"
    "% cd ..\n",
    "!model-archiver --model-name fer --model-path ./fer --handler fer_service:handle\n",
    "!ls -l fer.mar"
   ]
  },
  {
@@ -1175,18 +1176,22 @@
    "# Step 11 - Serving the model archive with MXNet Model Server\n",
    "\n",
    "Now that we have the model archive ready, we can start the server and ask it to setup HTTP endpoints to serve the model, emit real-time operational metrics and more.\n",
    "To learn more about serving, check out the [MMS Serving docs](https://github.com/awslabs/mxnet-model-server/blob/master/docs/server.md)."
    "To learn more about serving, check out the [MMS Serving docs](https://github.com/awslabs/mxnet-model-server/blob/master/docs/server.md).\n",
    "\n",
    "To start the server and load the FER model on startup, go to the console and run:  \n",
    "`\n",
    "$ mxnet-model-server --models fer=fer.mar --model-store .\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawning a new process to run the server\n",
    "import subprocess as sp\n",
    "server = sp.Popen(\"mxnet-model-server --models ferplus=ferplus.model\", shell=True)"
    "# Check out the health endpoint to make sure model server is running\n",
    "!curl http://127.0.0.1:8080/ping"
   ]
  },
  {
@@ -1195,70 +1200,45 @@
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the health endpoint\n",
    "!curl http://127.0.0.1:8080/ping"
    "# Call MMS management API to see list of loaded models\n",
    "!curl http://localhost:8081/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the loaded FER model\n",
    "!curl http://localhost:8081/models/fer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make a prediction request with a test image:\n",
    "![Happiness](../assets/happy.jpg)"
    "![Neutral](../assets/neutral-sad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"prediction\": [\r\n",
      "    {\r\n",
      "      \"neutral\": 0.3882121741771698\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"happiness\": 0.5335745811462402\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"surprise\": 0.002491839462891221\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"sadness\": 0.05849442631006241\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"anger\": 0.008850697427988052\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"disgust\": 0.0009525333880446851\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"fear\": 0.0007643798599019647\r\n",
      "    }, \r\n",
      "    {\r\n",
      "      \"contempt\": 0.006659356877207756\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "outputs": [],
   "source": [
    "!curl -X POST http://127.0.0.1:8080/ferplus/predict -F \"data=@../../assets/happy.jpg\""
    "!curl -X POST http://127.0.0.1:8080/fer/predict -T \"../assets/neutral-sad.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "cell_type": "markdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we'll terminate the server\n",
    "server.terminate()"
    "Lastly, to stop the server we will go to the console and run:  \n",
    "`\n",
    "$ mxnet-model-server --stop\n",
    "`"
   ]
  },
  {
